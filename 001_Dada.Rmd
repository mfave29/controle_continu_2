---
title: "Contrôle continu 2 - Ecogénomique 2 - Rade de Brest"
output: 
  github_document:
    toc: true
    toc_depth: 2
---


# Introduction

A travers les différentes approches bioinformatiques utilisées, l'objectif était de voir les influences relatives que pouvaient entraîner la profondeur et la saison sur la structure des communautés planctoniques de la rade de Brest. Enfin, nous voulions voir s'il existait des biomarqueurs de saison (hiver et été).


# Importation des données

Les données ont été importées. Il s'agit de prélèvements effectués dans la rade de Brest en 2014 et en 2015. Les données ont été définies dans un répertoire précis.

```{bash}
wget https://pagesperso.univ-brest.fr/~maignien/teaching/M1-MFA/UE-Ecogenomique2/EcoG2_data_cc2.tar.gz
tar xvzf EcoG2_data_cc2.tar.gz
```


```{r}
path <- "~/controle_continu_2/controle_continu_2/Stratif_CC2"
list.files(path)
```

Cette liste représente les 11 échantillons qui ont été prélevés, avec les reads 1 et 2 pour chaque échantillon. Il s'agit de fichiers fastq, des séquences associées à des scores de qualité. 


# Forward and Reverse
```{r}
fnFs <- sort(list.files(path, pattern="_R1.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2.fastq", full.names = TRUE))

sample.names <- sapply(strsplit(basename(fnFs), "_R"), `[`,1)
```

Les données ont été nommées selon qu'il s'agisse de reads 1 ou 2. La distinction a été effectuée en considérant la fin des titres des séquences.

# Profils de score de qualité 
```{r}
plotQualityProfile(fnFs[1:2])
```

Ici sont présentés les profiles des scores de qualité des forwards de deux échantillons différents. Le score de qualité moyen correspond à la ligne verte.  
Les premières lectures sont de bonne qualité. Plus on fait de lectures, moins la qualité est bonne. C'est pour cela qu'on filtrera plus tard. 

Nous faisons la même chose pour les mêmes échantillons, cette fois-ci avec les reverse : 

```{r}
plotQualityProfile(fnRs[1:2])
```

Nous pouvons constater que les read reverse sont de moins bonne qualité, ce qui apparaît souvent avec Illumina. Nous allons également découper. 


#Filtrage et coupures

Tout d'abord, nous attribuons des noms aux fichiers filtrés. Ainsi, les forward filtrés sont sauvegardés sous le nom de filtFs et les reverse filtrés sous le nom de filtRs.

```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```


```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250,220), trimLeft=c(21,21), maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, compress=TRUE, multithread = TRUE)
head(out)
```

Nous avons choisi de couper à 250 pb pour les forward. Cela a été fait à 220pb pour les reverse. Il était nécessaire d'avoir une séqence de 450 pb environ, car la région V4-V5 comporte ce nombre de pb environ. Il faut que les read se chevauchent.

Nous avions vu précédemment, par les graphiques, que la qualité des forward était meilleur que les reverse.
. 

Nous voyons que le filtrage a été effectué, le nombre de reads retenus étant inférieur aux reads avant le filtrage. 

Le paramètre trimLeft a été utilisé afin d'enlever les primers utilisés précédemment. 


# Apprendre le taux d'erreur

Les manipulations suivantes permettront de visualiser l'estimation des taux d'erreur et l'inférence de la composition de l'échantillon, afin de converger pour une meilleure cohérence. Nous faisons cela pour les Forward tout d'abord, puis pour les Reverse.

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

Il s'agit de nombre de bases qui seront utilisées pour l'apprentisssage du taux d'erreur pour les forward.

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
Il s'agit du nombre de bases qui seront utilisées pour l'apprentissage du taux d'erreur pour les Reverse.

Nous allons ensuite visualiser le taux d'erreurs, selon des erreurs de bases qui pourraient se produire. Cet exemple concerne les forward.
```{r}
plotErrors(errF, nominalQ=TRUE)
```


Nous voyons que les taux d'erreur ont une tendance à diminuer des lors que l'on obtient une qualité plus forte. Ainsi, nous pouvons considérer d'après ce graphique que tout semble bon. 

 
# Inférence des échantillons

Nous appliquons cela aux forward filtrés et découpés. Cela permet de faire des comparaisons. Nous commençons par les forward puis nous faisons cette manipulation pour les reverse.

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```


```{r}
dadaRs <- dada(filtRs, err=errR, multithread = TRUE)
```


```{r}
dadaFs[[1]]
```

Ce résultat signifie qu'il y a 937 variants de séquences à partir de 38016 séquences uniques pour le premier échantilon (Forward).



# Fusions des reads

La fusion des forward et des reverse permet d'avoir des séquences débruitées. Cela peut se faire par complémentarité inverse entre les forward et les reverse. Il y a formation de contigs. Il faut absolument qu'il y ait un certain chevauchement. 

La fonction "merge" permet de faire cela, tout en éliminant les paires qui ne se chevauchent pas donc, ou s'il y  trop de divergences dans cette région chevauchante. 
Le fait de mettre "verbose=TRUE" permet d'avoir une sortie sur le document. 

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
```


# Construction d'une table de séquence

Nous construisons une table ASV, pour Amplicon Sequence Variant table. 
Un variant de séquence d'amplicon est une séquence unique d'ADN. Ces variants sont créés après le filtrage que nous avons effectué auparavant. Cela permet la classification des séquences en groupement d'espèces. Cette méthode est plus précise que les OTU car la première permet de voir ne serait-ce qu'un changement de nucléotide. 

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

Nous voyons qu'il y a 11099 ASV dans les 11 échantillons. 

## Distribution des longueurs des séquences
```{r}
table(nchar(getSequences(seqtab)))
```
Nous avons les longueurs des séquences. 



# Elimination des chimères

Dada ne permet pas d'éliminer les chimères. Ceci est plus facile à faire à partir d'ASV en comparaison aux OTU. 

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```

```{r}
sum(seqtab.nochim)/sum(seqtab)
```


Nous voyons qu'il y a environ 20% de chimères. 


# Suivi des reads dans le pipeline
Ces tests permettent de voir à quel degré nous avons conservé les reads de départ. Comparer les pertes !!

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))

colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

Par exemple, pour l'échantillon du Fond1 prélevé le 10 septembre 2014, nous voyons qu'il y a une perte de 47% à peu près à la suite de filtrage, de débruitage et de fusion. 
Cela nous a permis de vérifier la cohérence. Nous voyons donc que le nombre a chuté à l'issue du filtrage. 


# Assignation de la taxonomie
Grâce à la fonction "assignTaxonomy", cela permet de classer les séquences avec une taxonomie connue. Nous prenons la base de données Silva. 

```{bash}
wget https://zenodo.org/record/1172783/files/silva_nr_v132_train_set.fa.gz
```


```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/controle_continu_2/controle_continu_2/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
```

Les taxons ont été assignés à une taxonomie particulière qui leur est propre.


Nous allons regarder les affectations taxonomiques : 

```{r}
taxa.print <- taxa
rownames(taxa.print) <- NULL
head(taxa.print)
```

Nous observons les 6 premiers taxons. 



# Evaluation de la précision

```{r}
unqs.mock <- seqtab.nochim["Mock"]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```
```{r}
samples.out <- rownames(seqtab.nochim)
profondeur <- sapply(strsplit(samples.out, "D"), `[`, 1)
date <- substr(profondeur,0,11)
samdf <- data.frame(Profondeur=profondeur, Date=date)
samdf$Profondeur[samdf$Date>11] <- c("Fond","Median","Surface")
samdf$Date[samdf$Profondeur>11] <- c("10sept14","11mars15")
rownames(samdf) <- samples.out
```

```{r}
write.csv(samdf, "samdf.csv")
```

```{r}
samdf <-read.table("~/controle_continu_2/controle_continu_2/samdf.csv", sep=",", header=TRUE, row.names = 1)
```


Le package phangorn doit être téléchargé et appliqué pour la construction d'un arbre phylogénétique plus tard. 
```{r}
library(phangorn)
library(DECIPHER)
seqs <- getSequences(seqtab.nochim)
names(seqs) <- seqs 
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) 
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```

```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa),phy_tree(fitGTR$tree))
ps
```


Accessoirement, nous pouvons voir une alpha-diversité.
```{r}
plot_richness(ps, x="Date", measures=c("Shannon", "Simpson"), color="Profondeur")
```


Pour voir les rangs présents dans le jeu de données, les codes suivants sont appliqués. Les taxa sont alors désignés en tant que Phylum.
```{r}
rank_names(ps)
```

```{r}
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```

A partir de notre jeu de données, et par les choix qui ont été réalisés, les Proteobacteria sont les plus représentés dans nos échantillons, suivis par les Bacteroidetes puis les Cyanobactéries. Les protéobactéries sont des bactéries à Gram négatif.

```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```


Nous évaluons ensuite la prévalence de chaque élément, présents dans le jeu de données.Ensuite, nous assignons la taxonomie et le nombre total à ce jeu de données.
```{r}
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})

prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```

Nous voulons ensuite voir s'il existe des Phylum ayant des faibles prévalences. 
```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

Nous remarquons que quelques Phylum ont une prévalence très faible, que nous excluons pour la suite de notre analyse. Il s'agit d'une étape de filtrage. 
```{r}
filterPhyla = c("Elusimicrobia", "Epsilonbacteraeota", "Fibrobacteres", "Hydrogenedentes", "Omnitrophicaeota", "PAUC34f")

ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```


Nous voulons visualiser la prévalence des phylum. Pour se faire, nous utilisons différentes fonctions. Ces graphiques montrent le lien entre la prévalence et l'abondance totale.
```{r}
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +

  geom_hline(yintercept = 0.15, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

Nous définissons ensuite un seuil de prévalence à 15%.
```{r}
prevalenceThreshold = 0.15 * nsamples(ps)
prevalenceThreshold
```

Nous faisons ensuite un filtrage de la prévalence en utilisant la fonction "prune_taxa", qui permet d'éliminer les taxons que l'on ne souhaite pas voir apparaître. Le jeu de données est alors assigné sous "ps2".
```{r}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```


# Agglomération des taxons
Nous voulons savoir combien de genres seront présents après le filtrage.
```{r}
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```

Il y a 95 genres présents.
Nous assignons alors ce résultat sous le nom de "ps3".
```{r}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```

Nous défissons ensuite la hauteur de l'arbre qu'on construira. La fonction "tip_glom" permet d'agglomérer les extrémités de l'arbre lorsque la distance est inférieur à 0.4.
```{r}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```


Nous voulons créer des arbres. Le premier permet d'en créer un avant l'agglomération, avec les données de "ps2". La deuxième fonction permet de créer un arbre selon le genre et la troisième fonction selon la hauteur de l'arbre.
```{r}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
```


```{r}
# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```

Nous remarquons qu'il y a moins d'extrémités lorsque nous construisons un arbre selon le genre.




# Transformation de la valeur d'abondance selon la profondeur

Ceci est rendu possible par la fonction "transform_sample_counts". La fonction "plot_abundance" permet de créer un graphique selon l'abondance relative.

Le Phylum qui est utilisé par la suite est celui des Actinobacteria. Ce choix est totalement arbitraire, il s'agit d'un exemple. 
```{r}
plot_abundance = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Actinobacteria"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "Profondeur",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```

Nous transformons donc le jeu de données en abondance relative, que nous enregistrons sous l'objet "ps3ra".
```{r}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```


Nous pouvons ensuite voir l'abondance après transformation.
```{r}
plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
grid.arrange(nrow = 2,  plotBefore, plotAfter)
```

Les ordres des Actinobacteria présents sont les Actinomarinales et les Microtrichales. Nous pouvons constater que les Actinomarinales sont présentes en plus grande abondance relative que les Microtrichales. Le premier ordre semblerait plus abondant dans les profondeurs de la rade de Brest qu'à la surface par exemple. Les Microtrichales quant à elles ne sembleraient pas abondantes dans une profondeur moyenne. Ceci est en corrélation avec le graphique des abondances en bar plot effectué précédemment.
En regardant "taxa_print", il s'avère que le genre qui appartient aux Actinomarinales est du genre des Candidatus. 


# Sous-ensemble par taxonomie
Nous spécifions un rang taxonomique plus précis. Comme dit précédemment, le seul genre des Actinomarinales présent est Candidatus. Nous constatons que ce genre est présent en plus grande abondance en profondeu, et semble être plus dispersé à la surface. 

```{r}
psOrd = subset_taxa(ps3ra, Order == "Actinomarinales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```


# Transformation de la valeur d'abondance selon la date

```{r}
plot_abundance1 = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Actinobacteria"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "Date",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```

```{r}
# Transform to relative abundance. Save as new object.
ps3ra1 = transform_sample_counts(ps3, function(x){x / sum(x)})
```

```{r}
plotBefore1 = plot_abundance1(ps3,"")
plotAfter1 = plot_abundance1(ps3ra1,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 2,  plotBefore1, plotAfter1)
```

Nous constatons une nouvelle fois que les Actinomarinales semblent plus abondants que les Microtrichales et cela, peu qu'importe la date, donc la saison. Les Actinomarinales sembleraient abondants aussi bien en fin d'été qu'en fin de la saison d'hiver. Concernant les Microtrichales, il s'avère que les données sont un peu plus dispersées mais il y aurait une légère tendance à une abondance relative plus importante à l'approche du printemps que quelques jours avant l'automne. 



```{r}
psOrd1 = subset_taxa(ps3ra1, Order == "Actinomarinales")
plot_abundance1(psOrd1, Facet = "Genus", Color = NULL)
```

Bien que les données ne sont pas très nettes, ce genre semble plus présent en fin de saison hivernale, même si rien n'est réellement précis.


```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(tax_table) tax_table/sum(tax_table))
ord.pcoa.bray <- ordinate(ps.prop, method="PCoA", distance="bray")
```



## Visualisation de l'ordination

```{r}
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "PCoA", distance = "bray")
```

```{r}
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "Profondeur", shape="Date") +
  labs(col = "Profondeur",shape= "Date")
```

Nous remarquons que les échantillons sont corrélés selon la profondeur et la saison. Nous remarquons une probable correspondance entre les échantillons profonds et de surface pour la saison d'hiver. Cela sera confirmé par la suite, en regardant l'abondance des Phylum et des genres, où on voit une faible différence d'abondance. 

# Visualisation de l'abondance des différents phylums

Nous pouvons en plus créer un graphique représentant l'abondance des différents phylums selon la date.
```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Date", fill="Phylum") + facet_wrap(~Profondeur, scales="free_x")
```

Nous remarquons que quelque soit la date et la profondeur, les protéobactéries sont les plus abondantes. Nous voyons en plus que pour les cyanobactéries, ces espèces sont retrouvées en plus grande abondance dans une profondeur moyenne et à la surface de la rade de Brest. 

Nous pouvons faire une analyse plus précise pour voir les genres les plus abondants. Pour ceci, nous faisons le même code qu'avant, en remplaçant "Phylum" par "Genus".
```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Date", fill="Genus") + facet_wrap(~Profondeur, scales="free_x")
```

Nous remarquons ainsi que dans les profondeurs, le genre le plus abondant est "Clade_Ia" quelque soit la saison. En moyenne profondeur, il semblerait que Synechococcus et Clade_IA soit en abondance relative plus ou moins égale. Par contre, à la surface de la rade de Brest, le genre le plus abondant en été est Synechococcus tandis qu'en hiver, il n'y en a pas, ou non visible du moins sur ces graphiques.
Dans la littérature, il est prouvé que Synechococcus sembleraient toutes photoautotrophes obligatoires, c'est pour cette raison que leur abondance est très basse dans l'environnement profond. La prolifération des cyanobactéries, dont font partis les Synechococcus est meilleure quand les eaux sont relativement plus chaudes. C'est donc pour cette raison qu'on les retrouve préférentiellement en été plutôt qu'en hiver. 



# Conclusion
A travers ces méthodes bioinformatiques, nous avons pu, à partir d'un jeu de données, apprécier les abondances différentielles des microorganismes dans les eaux de la rade de Brest. Les échantillonnages ont eu lieu lors de deux saisons différentes : en hiver et en été. Egalement, il y a eu des prélèvements avec des profondeurs différentes : au fond, à une profondeur moyenne et à la surface. 
Après toutes les étapes qui ont été faites, de l'échantillonnage jusqu'à l'appréciation de l'abondance des microorganismes en passant par des étapes de filtrage et de transformation, nous pouvons conclure qu'il existe un lien entre les abondances de bactéries, les saisons et les profondeurs. Les Synechococcus représentent des biomarqueurs dans les zones eutrophiques, photiques avec une température minimale nécessaire. 

























